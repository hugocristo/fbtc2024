# detecta prescrições nos posts
for (linha in 1:nrow(frases.nao.texto)) {
prescricoes <- str_extract_all(frases.nao.texto$caption[linha], "não\\s\\w{1,}\\s\\w{1,}\\s\\w{1,}", simplify = TRUE)
# prescrições do post
for (p in 1:length(prescricoes)) {
# adiciona coluna
frases.nao.texto[linha,str_c("prescricao_",p)] <- prescricoes[p]
}
}
View(frases.nao.texto)
View(frases.nao.texto)
# seleciona banco
banco <- read_xlsx("./dados/banco-completo.xlsx")
tapply(banco,banco$ownerUsername,count)
tapply(banco,banco$ownerUsername,length)
# seleciona banco
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
tapply(banco,banco$ownerUsername,length)
# -----------------------------------------------------------
# 03-prescricoes.R
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
library (readxl)
library (stringr)
# seleciona banco
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# tranforma texto para minísculas
banco$caption <- str_to_lower(banco$caption, locale="pt")
# detecta ocorrências nos textos dos posts (não + 4 palavras)
frases.nao <- which(str_detect(banco$caption, "não\\s\\w{1,}\\s\\w{1,}\\s\\w{1,}"))
# limita colunas da análise (1-4)
frases.nao.texto <- banco[frases.nao,1:4]
# detecta prescrições nos posts
for (linha in 1:nrow(frases.nao.texto)) {
prescricoes <- str_extract_all(frases.nao.texto$caption[linha], "não\\s\\w{1,}\\s\\w{1,}\\s\\w{1,}", simplify = TRUE)
# prescrições do post
for (p in 1:length(prescricoes)) {
# adiciona coluna
frases.nao.texto[linha,str_c("prescricao_",p)] <- prescricoes[p]
}
}
# exibe
View(frases.nao.texto)
# seleciona banco
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
View(banco)
# -----------------------------------------------------------
# 03-prescricoes.R
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
library (readxl)
library (stringr)
# seleciona banco
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# tranforma texto para minísculas
banco$caption <- str_to_lower(banco$caption, locale="pt")
# detecta ocorrências nos textos dos posts (não + 4 palavras)
frases.nao <- which(str_detect(banco$caption, "não\\s\\w{1,}\\s\\w{1,}\\s\\w{1,}"))
# limita colunas da análise (1-4)
frases.nao.texto <- banco[frases.nao,1:2]
# detecta prescrições nos posts
for (linha in 1:nrow(frases.nao.texto)) {
prescricoes <- str_extract_all(frases.nao.texto$caption[linha], "não\\s\\w{1,}\\s\\w{1,}\\s\\w{1,}", simplify = TRUE)
# prescrições do post
for (p in 1:length(prescricoes)) {
# adiciona coluna
frases.nao.texto[linha,str_c("prescricao_",p)] <- prescricoes[p]
}
}
# exibe
View(frases.nao.texto)
frases.nao.texto$caption[13]
View(frases.nao.texto)
# -----------------------------------------------------------
# 03-prescricoes.R - atualizado em 12/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library (readxl)
library (stringr)
# seleciona banco
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# tranforma texto para minísculas
banco$caption <- str_to_lower(banco$caption, locale="pt")
# detecta ocorrências nos textos dos posts (não + 4 palavras)
frases.nao <- which(str_detect(banco$caption, "não\\s\\w{1,}\\s\\w{1,}\\s\\w{1,}"))
# limita colunas da análise (1-4)
frases.nao.texto <- banco[frases.nao,1:2]
# detecta prescrições nos posts
for (linha in 1:nrow(frases.nao.texto)) {
prescricoes <- str_extract_all(frases.nao.texto$caption[linha], "não\\s\\w{1,}\\s\\w{1,}\\s\\w{1,}", simplify = TRUE)
# prescrições do post
for (p in 1:length(prescricoes)) {
# adiciona coluna
frases.nao.texto[linha,str_c("prescricao_",p)] <- prescricoes[p]
}
}
# exibe resultado
View(frases.nao.texto)
# -----------------------------------------------------------
# 01-nuvem-palavras.R - atualizado em 12/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library (readxl)
library (wordcloud2)
banco <- read_xlsx("./dados/lista-palavras.xlsx")
wordcloud2(lista.hashtags.freq, size=1.6, color='random-dark')
# -----------------------------------------------------------
# 01-nuvem-palavras.R - atualizado em 12/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library (readxl)
library (wordcloud2)
banco <- read_xlsx("./dados/lista-palavras.xlsx")
wordcloud2(banco, size=1.6, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 5,], size=1.6, color='random-dark')
View(banco)
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 10,], size=1.6, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 10,], size=1.6, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 15,], size=1.6, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 15,], size=1.6, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 15,], size=1.6, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 20,], size=1.6, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 15,], size=1.2, color='random-dark')
# nuvem de palavras com frequência > 5
wordcloud2(banco[banco$frequencia > 15,], size=1, color='random-dark')
# -----------------------------------------------------------
# 01-gera-lista-palavras.R - atualizado em 12/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library (readxl)
library (stringr)
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
hashtags <- data.frame()
# cria vetor linhas de todas as hashtags não vazias
for (coluna in 5:21) {
quais.hashtags <- which(!is.na(banco[,coluna]))
lista.hashtags <- banco[quais.hashtags,coluna]
print(lista.hashtags)
# adiciona ao banco
for (h in 1:nrow(lista.hashtags)) {
hashtags <- rbind(hashtags, data.frame(
"hashtag"=as.character(lista.hashtags[h,1]),
stringsAsFactors = FALSE
))
}
}
# únicas
hashtags.unicas <- unique(hashtags)
hashtags.unicas$freq <- 0
# conta
for (h in 1:nrow(hashtags.unicas)) {
ht <- hashtags.unicas$hashtag[h]
total <- sum(str_count(ht,hashtags$hashtag))
cat(ht,":",total,"\n")
hashtags.unicas$freq[h] <- total
}
View(lista.hashtags)
View(hashtags.unicas)
View(hashtags.unicas)
View(hashtags.unicas)
# -----------------------------------------------------------
# 04-gera-lista-hashtags.R - atualizado em 12/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library (readxl)
library (stringr)
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# data.frame para hashtags
hashtags <- data.frame()
# cria vetor linhas de todas as hashtags não vazias
for (coluna in 5:21) {
quais.hashtags <- which(!is.na(banco[,coluna]))
lista.hashtags <- banco[quais.hashtags,coluna]
print(lista.hashtags)
# adiciona ao banco
for (h in 1:nrow(lista.hashtags)) {
hashtags <- rbind(hashtags, data.frame(
"hashtag"=as.character(lista.hashtags[h,1]),
stringsAsFactors = FALSE
))
}
}
# únicas
hashtags.unicas <- unique(hashtags)
# define frequência zero
hashtags.unicas$freq <- 0
# contagem
for (h in 1:nrow(hashtags.unicas)) {
ht <- hashtags.unicas$hashtag[h]
total <- sum(str_count(ht,hashtags$hashtag))
# saída para o usuário
cat(ht,":",total,"\n")
# define total
hashtags.unicas$freq[h] <- total
}
# exibe banco resultante
View(hashtags.unicas)
# exporta banco como CSV
# write.csv2(hashtags.unicas,"lista-hashtags-unicas.csv")
# -----------------------------------------------------------
# 01-gera-lista-palavras.R - atualizado em 12/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
remotes::install_github("hadley/emo")
library (readxl)
library (stringr)
library(emo)
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# hapáx
remover.palavras <- c("da","das","de","do","dos",
"com","como","que","por","para",
"a","as","à","às","o","os","em","é","e","que",
"se","mas","um","uns",
"na","nas","no","nos",
"ou", "está", "seu", "sua", "seus", "suas",
"isso", "disso", "esse", "desse", "esses", "desses",
"essa", "dessa", "essas", "dessas",
"aquele", "aquela", "este", "estes")
remover.pontuacao <- c("\\“","\\”","\\?","\\!",
"\\:","\\,","\\.","\"",
"\\)","\\(","\\.\\.\\.")
# seleciona posts
posts <- banco$caption
# cria df com palavras dos posts
lista.palavras <- data.frame()
# laço pelos posts
for (t in 1:length(posts)) {
# se o post não estiver vazio
if (!is.na(posts[t])) {
# transforma hífen sozinho no início da linha em espaço (tópico)
posts[t] <- str_replace_all(posts[t],"^\\-","")
# remove traços isolados
posts[t] <- str_replace_all(posts[t],"\\s\\-\\s"," ")
# remove reticências
posts[t] <- str_replace_all(posts[t],"…"," ")
# remove caracteres bizarros e números
posts[t] <- str_replace_all(posts[t],"[:digit:]|⠀|⬇|☡|—|___|✔|❤"," ")
# remove quebras de linha
posts[t] <- str_replace_all(posts[t],"\\r\\n"," ")
# remove hapáx e emoji
posts[t] <- str_replace_all(posts[t],str_c("\\b",remover.palavras,"\\b",collapse="|"),"")
posts[t] <- str_remove_all(posts[t],str_c(remover.pontuacao,collapse="|"))
# remove pontuação
posts[t] <- str_remove_all(posts[t],str_c(remover.pontuacao,collapse="|"))
# remove emojis (hadley/emo)
posts[t] <- ji_replace_all(posts[t],"")
# remove espaços duplos
posts[t] <- str_squish(posts[t])
# remove pontuação
#posts[t] <- removePunctuation(posts[t])
# caixa baixa e únicos
posts[t] <- str_to_lower(posts[t],locale="pt")
# quebra texto em palavras
post <- str_split(posts[t],"\\s", simplify = TRUE)
# importa para o df
lista.palavras <- rbind(lista.palavras,data.frame("palavra"=as.character(post), stringsAsFactors = FALSE))
}
}
# remove duplicadas
lista.palavras.unicas <- unique(lista.palavras$palavra)
# novo dataframe
lista.palavras.freq <- data.frame("palavra"=lista.palavras.unicas,"freq"=rep(0,length(lista.palavras.unicas)), stringsAsFactors = FALSE)
# exporta lista de palavras
#write.csv2(lista.palavras.freq,"lista.palavras.csv")
# -----------------------------------------------------------
# 01-gera-lista-palavras.R - atualizado em 12/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
remotes::install_github("hadley/emo")
library (readxl)
library (stringr)
library(emo)
banco <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# hapáx
remover.palavras <- c("da","das","de","do","dos",
"com","como","que","por","para",
"a","as","à","às","o","os","em","é","e","que",
"se","mas","um","uns",
"na","nas","no","nos",
"ou", "está", "seu", "sua", "seus", "suas",
"isso", "disso", "esse", "desse", "esses", "desses",
"essa", "dessa", "essas", "dessas",
"aquele", "aquela", "este", "estes")
remover.pontuacao <- c("\\“","\\”","\\?","\\!",
"\\:","\\,","\\.","\"",
"\\)","\\(","\\.\\.\\.")
# seleciona posts
posts <- banco$caption
# cria df com palavras dos posts
lista.palavras <- data.frame()
# laço pelos posts
for (t in 1:length(posts)) {
# se o post não estiver vazio
if (!is.na(posts[t])) {
# transforma hífen sozinho no início da linha em espaço (tópico)
posts[t] <- str_replace_all(posts[t],"^\\-","")
# remove traços isolados
posts[t] <- str_replace_all(posts[t],"\\s\\-\\s"," ")
# remove reticências
posts[t] <- str_replace_all(posts[t],"…"," ")
# remove caracteres bizarros e números
posts[t] <- str_replace_all(posts[t],"[:digit:]|⠀|⬇|☡|—|___|✔|❤"," ")
# remove quebras de linha
posts[t] <- str_replace_all(posts[t],"\\r\\n"," ")
# remove hapáx e emoji
posts[t] <- str_replace_all(posts[t],str_c("\\b",remover.palavras,"\\b",collapse="|"),"")
posts[t] <- str_remove_all(posts[t],str_c(remover.pontuacao,collapse="|"))
# remove pontuação
posts[t] <- str_remove_all(posts[t],str_c(remover.pontuacao,collapse="|"))
# remove emojis (hadley/emo)
posts[t] <- ji_replace_all(posts[t],"")
# remove espaços duplos
posts[t] <- str_squish(posts[t])
# remove pontuação
#posts[t] <- removePunctuation(posts[t])
# caixa baixa e únicos
posts[t] <- str_to_lower(posts[t],locale="pt")
# quebra texto em palavras
post <- str_split(posts[t],"\\s", simplify = TRUE)
# importa para o df
lista.palavras <- rbind(lista.palavras,data.frame("palavra"=as.character(post), stringsAsFactors = FALSE))
}
}
# remove duplicadas
lista.palavras.unicas <- unique(lista.palavras$palavra)
# novo dataframe
lista.palavras.freq <- data.frame("palavra"=lista.palavras.unicas,"freq"=rep(0,length(lista.palavras.unicas)), stringsAsFactors = FALSE)
# exporta lista de palavras
#write.csv2(lista.palavras.freq,"lista.palavras.csv")
View(lista.palavras.freq)
View(lista.palavras)
for (p in 1:nrow(banco)) {
linha.hash <- c()
for (h in 5:26) {
if (!is.na(banco[p,h])) {
cat("encontrei:",as.character(banco[p,h]),"\n")
linha.hash <- c(linha.hash, str_to_lower(as.character(banco[p,h])))
}
}
print(linha.hash)
if (length(linha.hash) > 0) {
banco$hashtags[p] <- str_c(linha.hash,collapse="; ")
}
}
View(lista.palavras.freq)
View(banco)
# -----------------------------------------------------------
# 06-estatisticas.R - atualizado em 13/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library('ggplot2')
# corrige notação matemática
options(scipen=100, digits=4)
# importa banco completo
banco.completo <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# -----------------------------------------------------------
# 06-estatisticas.R - atualizado em 13/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library('ggplot2')
# corrige notação matemática
options(scipen=100, digits=4)
# importa banco completo
banco.completo <- read_xlsx("./dados/banco-completo.xlsx")
# -----------------------------------------------------------
# 06-estatisticas.R - atualizado em 13/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library(ggplot2)
library(readxl)
library(stringr)
# corrige notação matemática
options(scipen=100, digits=4)
# importa banco completo
banco.completo <- read_xlsx("./dados/banco-completo.xlsx")
# -----------------------------------------------------------
# 06-estatisticas.R - atualizado em 13/04/2024
# -----------------------------------------------------------
# FBTC 2014 - Kátia Cristina de Paula e Hugo Cristo Sant'Anna
# Universidade Federal do Espírito Santo
# Programa de Pós-Graduação em Psicologia
# https://github.com/hugocristo/fbtc2024
# -----------------------------------------------------------
library(ggplot2)
library(readxl)
library(stringr)
# corrige notação matemática
options(scipen=100, digits=4)
# importa banco completo
banco.completo <- read_xlsx("./dados/banco-completo-anonimo.xlsx")
# para calcular a soma dos likes
tapply(banco.completo$likesCount, banco.completo$ownerUsername, sum, simplify = TRUE)
likes.por.perfil <- as.data.frame(tapply(banco.completo$likesCount, banco.completo$ownerUsername, sum, simplify = TRUE))
colnames(likes.por.perfil) <- c("likes")
# para calcular a soma dos comentários
tapply(banco.completo$commentsCount, banco.completo$ownerUsername, sum, simplify = TRUE)
comentarios.por.perfil <- data.frame(tapply(banco.completo$commentsCount, banco.completo$ownerUsername, sum, simplify = TRUE))
colnames(comentarios.por.perfil) <- c("comentarios")
# =====================================
# cria df para calcular correlações
# =====================================
# converte nomes das linhas em linhas
perfis <- row.names(comentarios.por.perfil)
# copia para novo df
estatisticas.por.perfil <- data.frame("perfis"=perfis)
# incluir likes e comentários
estatisticas.por.perfil$likes <- likes.por.perfil$likes
estatisticas.por.perfil$comentarios <- comentarios.por.perfil$comentarios
estatisticas.por.perfil$perfis <- as.factor(estatisticas.por.perfil$perfis)
# seguidores
seguidores.por.perfil <- read_xlsx('./dados/seguidores-por-perfil.xlsx')
# correlação (plotar e visualizar)
cor.test(estatisticas.por.perfil$likes, estatisticas.por.perfil$comentarios)
# testa correlação no banco completo
cor.test(banco.completo$likesCount, banco.completo$commentsCount)
# gera tabela de correlação de todos os perfis
tabela.correlacoes <- data.frame()
for (perfil in 1:length(unique(banco.completo$ownerUsername))) {
# seleciona usuário da lista
usuario <- unique(banco.completo$ownerUsername)[perfil]
if (length(banco.completo[banco.completo$ownerUsername == usuario,]$likesCount) > 1) {
# testa este usuário
teste <- cor.test(banco.completo[banco.completo$ownerUsername == usuario,]$likesCount,
banco.completo[banco.completo$ownerUsername == usuario,]$commentsCount)
# registra resultado do teste
tabela.correlacoes <- rbind(tabela.correlacoes, data.frame(
"perfil"=usuario,
"r"=teste$estimate,
"ci_inf"=teste$conf.int[1],
"ci_sup"=teste$conf.int[2],
"p"=teste$p.value,
stringsAsFactors = TRUE
))
}
}
# gráfico dos intervalos de correlações com ggplot2
ggplot(data=tabela.correlacoes) +
geom_hline(aes(yintercept=0.5), linetype="dashed", colour="gray")+
geom_segment(aes(x=perfil, y=ci_inf, xend=perfil, yend=ci_sup, colour=perfil)) +
geom_point(aes(x=perfil, y=r, colour=perfil)) +
geom_text(aes(x=perfil, y=r, label=ifelse(p < 0.05, str_c(round(r,2),"*"),round(r,2)), vjust=0), size=3, nudge_x=0.3) +
coord_flip() +
xlab("Curtidas") + ylab("Comentários") +
labs(title="Correlação de Pearson (r) entre curtidas e comentários",subtitle="* p < 0.01")+
theme_minimal() +
theme(
legend.position = "none",
axis.title.x = element_text(margin=margin(12,0,0,0,unit="pt")),
axis.title.y = element_text(margin=margin(0,12,0,0,unit="pt"))
)
# exporta tabela de correlações
#write.csv2(tabela.correlacoes,"./dados/tabela-correlacoes.csv")
# exporta estatísticas por perfil
#write.csv2(estatisticas.por.perfil,"./dados/estatisticas-por-perfil.csv")
View(tabela.correlacoes)
View(estatisticas.por.perfil)
# exporta estatísticas por perfil
write.csv2(estatisticas.por.perfil,"./dados/estatisticas-por-perfil.csv")
